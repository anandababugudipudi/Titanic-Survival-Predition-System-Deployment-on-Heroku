{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P-u6axwpHmWS"
   },
   "source": [
    "# **Titanic Survival Prediction Using Machine Learning**\n",
    "\n",
    "The [RMS Titanic](https://en.wikipedia.org/wiki/RMS_Titanic) was known as the unsinkable ship and was the largest, most luxurious passenger ship of its time. Sadly, the British ocean liner sank on April 15, 1912, killing over 1500 people while just 705 survived. In this article, we will analyze the Titanic data set and make predictions to see whether passengers on board the ship would survive or not.\n",
    "\n",
    "The following are the steps involved in this project:\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Let's start implementing the above steps one by one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xsRbDRPvIVRe"
   },
   "source": [
    "###**Import the necessary packages**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UI0yRDgaIZ4j"
   },
   "outputs": [],
   "source": [
    "#Import Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pADuNTxhIfoD"
   },
   "source": [
    "###**Data Collection**\n",
    "\n",
    "The Train and Test Datasets are downloaed from Kaggle Datasets. One can download the data files from [here](https://www.kaggle.com/c/titanic/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ihWT9ODFI6dj"
   },
   "source": [
    "###**Loading the Dataset**\n",
    "\n",
    "We can load the dataset which is in the `.csv` fromat using `pd.read_csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SdHplDmwJHRz"
   },
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "train_data = pd.read_csv('./dataset/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 359
    },
    "id": "1Zf3UnALJnr_",
    "outputId": "18440088-9a3a-4720-bd1c-5e7e24b84278"
   },
   "outputs": [],
   "source": [
    "# Print the first 10 rows fo data\n",
    "train_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ulVQb3yBKdoh",
    "outputId": "0ccafe21-6e51-4ba3-d13d-2a6a2803bd48"
   },
   "outputs": [],
   "source": [
    "# Check the size of dataset\n",
    "train_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y40iX2M9O7tR"
   },
   "source": [
    "#####**Description of the Dataset**\n",
    "\n",
    "The dataset has 891 records with 12 columns. The details of each column are provided in the below table;\n",
    "\n",
    "| Variable |\tDefinition |\tKey |\n",
    "| -- | -- | :--: | \n",
    "| PassengerID | Unique ID of Passenger | |\n",
    "| Survivad |\tIf a passenger survived or not |\t0 = No, 1 = Yes |\n",
    "| Pclass |\tTicket class of passenger |\t1 = 1st, 2 = 2nd, 3 = 3rd |\n",
    "| Name | Name of the passenger | |\n",
    "| Sex\t| Gender of the passenger | |\t\n",
    "| Age |\tAge of passenger in years\t| |\n",
    "| SbiSp |\t# of siblings / spouses aboard the Titanic\t| |\n",
    "| Parch\t| # of parents / children aboard the Titanic\t| |\n",
    "| Ticket |\tTicket number\t| |\n",
    "| Fare\t| Passenger fare\t| |\n",
    "| Cabin\t| Cabin number\t| |\n",
    "| Embarked\t| Port of Embarkation |\tC = Cherbourg, Q = Queenstown, S = Southampton |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z-3rkh5Mtz7S"
   },
   "source": [
    "###**Feature Engineering**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FvxhejGot06S"
   },
   "source": [
    "#####**Dealing with null values**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Br_7ib1Dt4JC",
    "outputId": "3a6a6757-45c6-4727-be52-a111f2f58288"
   },
   "outputs": [],
   "source": [
    "# Check how many columns has missing values\n",
    "train_data.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dvpE6MZxuQni"
   },
   "source": [
    "There are missing values in the columns Age, Cabin and Embarked\n",
    "\n",
    "    `Age` --> 177\n",
    "\n",
    "    `Cabin` --> 687\n",
    "\n",
    "    `Embarked` --> 2\n",
    "\n",
    "So, we have to deal with these missing values in a reasonable way. We can do that in two ways:\n",
    "1. Deleting those records which are having missing values (This will lead to loss of data)\n",
    "2. Replace the missin information with relevant info \n",
    "  - Replacing numerical data with mean of the column and \n",
    "  - Replacing categorical data with frequently occured value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3gZb2ayXvTzH"
   },
   "outputs": [],
   "source": [
    "# Delete the Cabin column as it has 687 missing values\n",
    "train_data.drop(['Cabin'], axis = 1, inplace = True)\n",
    "# Filling the missing information\n",
    "train_data = train_data.apply(\n",
    "    lambda x : x.fillna(x.mean() if (x.dtype == \"float\") else x.fillna(x.value_counts().index[0]))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BzsFpJznvwnU",
    "outputId": "911ed622-3bb1-4002-e57a-85ca51573800"
   },
   "outputs": [],
   "source": [
    "# Let's chek the dataset once\n",
    "train_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wnqJBJ9Qv6w9"
   },
   "source": [
    "We can observe that all the missing information is filled with appropriate data from the dataframe.\n",
    "\n",
    "The methods `.isna()` and `.isnull()` yeilds the same information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hNfyVMhTUwsF"
   },
   "source": [
    "#####**Add/Delete the columns**\n",
    "\n",
    "All the columns that are present in the dataset are not important for the analysis. We will delete those which are not important like `PassengerID`, `Ticket` and `Name`.\n",
    "\n",
    "After that we will also add some features like whether a person is Man, Woman or Child and whether a passenger is an adult male or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Gwar-ezvVZsD"
   },
   "outputs": [],
   "source": [
    "# Drop the 3 unnecessary columns\n",
    "cols_drop = ['PassengerId', 'Name', 'Ticket']\n",
    "train_data.drop(cols_drop, axis = 1, inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n19Fwep4WPOi"
   },
   "outputs": [],
   "source": [
    "# Add the 2 columns\n",
    "# Conditions, values and adding column for 'who'\n",
    "conditions = [\n",
    "              (train_data['Age'] < 18),\n",
    "              ((train_data['Age'] >= 18) & (train_data['Sex'] == 'female')),\n",
    "              ((train_data['Age'] >= 18) & (train_data['Sex'] == 'male')) \n",
    "             ]\n",
    "values = ['child', 'woman', 'man']\n",
    "train_data['Who'] = np.select(conditions, values)\n",
    "\n",
    "# Conditions, values and adding column for 'adult_male'\n",
    "train_data['Adult_male'] = np.select(\n",
    "    [((train_data['Age'] >= 18) & (train_data['Sex'] == 'male')),\n",
    "     ((train_data['Age'] < 18) | (train_data['Sex'] == 'female'))], \n",
    "    [True, False])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "I1af1Y6md1kE",
    "outputId": "373eb9df-b8a0-42e0-d48a-42b1e936f174"
   },
   "outputs": [],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xnIVlS2pRTQv"
   },
   "source": [
    "###**Exploratory Data Analysis**\n",
    "\n",
    "Let's study the data and bring out some interesting facts about it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 297
    },
    "id": "IqITFPPERftb",
    "outputId": "db97c4c1-2620-44f7-c2d9-7ff5a5a2db9e"
   },
   "outputs": [],
   "source": [
    "# Check the statical feature of numerical data\n",
    "train_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "id": "KD66Od4ieg0U",
    "outputId": "97f15fb4-c007-4d62-cc32-55c57cc6f3ac"
   },
   "outputs": [],
   "source": [
    "# Check the statical feature of categorical data\n",
    "train_data.describe(include = 'O')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o6bVsIxvR7gr"
   },
   "source": [
    "#####**Observations:**\n",
    "- **Fare:** We can observe that the max price/fare a passenger paid for a ticket in this data set was 512.3292 British pounds, and the minimum price/fare was 0 British pounds with an average price/fare of 32.204208 British pounds.\n",
    "\n",
    "- **Age:** The mean age of passengers is 29.699 and the oldest passenger on the ship was 80 years old, while the youngest was only 0.42 years old (about 5 months).\n",
    "\n",
    "- **Missing Data:** We can also see that there is some missing data for the age column as it’s less than 891 (the number of passengers in this data set)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CKtRm5G8S9NJ"
   },
   "source": [
    "#####**Check for the number of survivors on board the Titanic**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 350
    },
    "id": "ffeWVHXhSt6V",
    "outputId": "7859d674-a793-4be0-8ad3-3c3fe7149f3f"
   },
   "outputs": [],
   "source": [
    "# Getting a count of number of survivors on board the Titanic\n",
    "train_data['Survived'].value_counts()\n",
    "\n",
    "# Visualise the count of number of survivors\n",
    "sns.countplot(train_data['Survived'], label = \"Count\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y4pnwdL2TKXU"
   },
   "source": [
    "#####**Observations:**\n",
    "According to the data, among the 891 people only 342 could survive and 549 people have died.\n",
    "\n",
    "<img src = \"images/1. survived.png\" width = \"600\" height = \"300\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yQ91F2DIq9R-"
   },
   "source": [
    "#####**Visualize the count of survivors for some columns**\n",
    "\n",
    "Now let's visualize the count of survivors for the columns `Who, Sex, Pclass, SibSp, Parch`, and `Embarked`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JzM9SyQErOGR",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Visualize the count of survivors for the columns who, sex, pclass, sibsp, parch, and embarked.\n",
    "cols = ['Who', 'Sex', 'Pclass', 'SibSp', 'Parch', 'Embarked']\n",
    "\n",
    "n_rows = 2\n",
    "n_cols = 3\n",
    "\n",
    "fig, axs = plt.subplots(n_rows, n_cols, figsize = (n_cols * 3.2 , n_rows * 3.2))\n",
    "\n",
    "for row in range(n_rows):\n",
    "  for col in range(n_cols):\n",
    "    i = row * n_cols + col  # Index to go through the number of cols\n",
    "    ax = axs[row][col]    # Show where to position each subplot\n",
    "    sns.countplot(train_data[cols[i]], hue = train_data['Survived'], ax = ax)\n",
    "    ax.set_title(cols[i])\n",
    "    ax.legend(title = \"Survived\", loc = \"upper right\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yPQmyDtow2h6"
   },
   "source": [
    "#####**Observations:**\n",
    "We can observe the following things whether a person has survival chances or not according to the charts given below.\n",
    "\n",
    "<img src = \"images/2. cols vs survived.png\" width = \"800\" height = \"500\">\n",
    "\n",
    "| Chart Title | Observation |\n",
    "| :---------: | :---------- |\n",
    "| Who | A man is not likely to survive. |\n",
    "| Sex | Females are most likely to survive |\n",
    "| Pclass | Third class is most likely to not survive |\n",
    "| SibSp | If you have 0 siblings or spouses on board, you are not likely to survive |\n",
    "| Parch | If you have 0 parents or children on board, you are not likely to survive | \n",
    "| Embarked | If you embarked from Southampton (S), you are not likely to survive |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9kzz3aIUyY9n"
   },
   "source": [
    "#####**Check for Survival rate by Sex**\n",
    "\n",
    "Now let's check the survival rate of a passenger onboard by sex."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SpUZDlu6yjj7"
   },
   "outputs": [],
   "source": [
    "# Check for Survival rate by sex\n",
    "train_data.groupby('Sex')[['Survived']].mean()\n",
    "\n",
    "# Plot the results\n",
    "sns.barplot(x = 'Sex', y = 'Survived', data = train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fHhiQuX5ywrK"
   },
   "source": [
    "#####**Observation:**\n",
    "From the results we can observe that about 74.2% of females survived and about 18.89% of males survived. \n",
    "\n",
    "<img src = \"images/3. Survival rate by Sex.png\" width = \"600\" height = \"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ACFygZAUzNBo"
   },
   "source": [
    "#####**Check for Survival rate by Sex and Class as well**\n",
    "\n",
    "Now let's check the survival rate of a passenger onboard by with their gender and class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6dmVv_UEzPAd"
   },
   "outputs": [],
   "source": [
    "# Look at the survival rate by sex and class\n",
    "train_data.pivot_table('Survived', index = 'Sex', columns = 'Pclass')\n",
    "\n",
    "# Plot the results as well\n",
    "sns.barplot(x = 'Pclass', y = 'Survived', data = train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mBxGobpUzOg7"
   },
   "source": [
    "#####**Observation:**\n",
    "From the results we can observe that:\n",
    "-  Females in the first class has the highest survival rate of about 96.80% (majority of them have survived). \n",
    "- Males in the third class has the lowest survival rate of about 13.54% (Majority of them have not survived).\n",
    "\n",
    "<img src = \"images/4. Survival rate by Class.png\" width = \"600\" height = \"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8FANTbRj1dLP"
   },
   "source": [
    "####**Check for Survival rate by Sex, Age, and Class**\n",
    "Now let's check for survival rate of passenger by Sex, Age, and Class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "p6WLxpK-1sfU",
    "outputId": "637a1f06-7e8b-483c-a941-dfafc2c37103"
   },
   "outputs": [],
   "source": [
    "# Survival rate by Sex, Age, and Class\n",
    "age = pd.cut(train_data['Age'], [0, 18, 80])    # Separating the age into 3 sub groups\n",
    "train_data.pivot_table('Survived', ['Sex', age], 'Pclass')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7jt1PmGt7UWT"
   },
   "source": [
    "#####**Observation:**\n",
    "\n",
    "We can see from the results that women in first class that were 18 and older had the highest survival rate at 97.59%, while men 18 and older in second class had the lowest survival rate of 8.62%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's delete the columns Who and Adult_Male as they have been created for better understanding of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.drop(['Who', 'Adult_male'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4O6lDUlf8g7I"
   },
   "source": [
    "###**Label Encoding of Categorical Columns**\n",
    "\n",
    "If we observe the data, some of the columns has categorical data types which are to be converted into numerical data types. For this we will use `LabelEncoder` from `sklearn.preprocessing`.\n",
    "\n",
    "Let's check the data type of each column and decide which columns are to be encoded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "M1jzzBsy9wK-",
    "outputId": "fe4e0e08-8c8d-48c0-88da-ecb356a7e7d1"
   },
   "outputs": [],
   "source": [
    "train_data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2Qxv052D92Ad"
   },
   "source": [
    "The results show that the columns `Sex`, `Embarked` columns are `object` datatypes. So we have to convert/encode them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4_fIqHvc-Fur"
   },
   "outputs": [],
   "source": [
    "# Category columns\n",
    "cat_cols = ['Sex', 'Embarked']\n",
    "for col in cat_cols:\n",
    "  print(train_data[col].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ssvosKgz-hg6"
   },
   "source": [
    "These are the unique values of each column\n",
    "\n",
    "- Sex: ['male' 'female']\n",
    "\n",
    "- Embarked :['S' 'C' 'Q']\n",
    "\n",
    "\n",
    "\n",
    "Now change the non-numeric data to numeric data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YvmB_3NC-wtK",
    "outputId": "a0846328-3c39-4af4-a567-5fef5608d7a3"
   },
   "outputs": [],
   "source": [
    "# Creating a LabelEncoder and transforming the values to numeric data\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "labelencoder = LabelEncoder()\n",
    "for col in cat_cols:\n",
    "  before = train_data[col].unique()\n",
    "  train_data[col] = labelencoder.fit_transform(train_data[col])\n",
    "  after = train_data[col].unique()\n",
    "  print(f\"{before} converted into {after}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "auiFokZf_h-o",
    "outputId": "be9814b7-d014-4bf9-8219-f79422334f5e",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Check the datapyes once again\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JLUVc4AtAYHf"
   },
   "source": [
    "###**Split the data into Features (X) and Targets (y)**\n",
    "\n",
    "We have the training dataset. Now we have to split the dataset into Features ( X or Dependant variable) and Targets(y or Independant variable)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rQy8ooGSAuSF"
   },
   "outputs": [],
   "source": [
    "# Split the data into Features and Labels\n",
    "X = train_data.drop(['Survived'], axis = 1)\n",
    "y = train_data['Survived']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "j1t_Xe8AA1JV",
    "outputId": "d40ec9de-1779-4581-acc5-c24543345c1f"
   },
   "source": [
    "Split the data into 80% training (X_train and y_train) and 20% testing (X_test and y_test) data sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into 80% Training set and 20% Testing set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###**Feaure Scaling**\n",
    "\n",
    "Now we have to scale the data. The data has to be scaled as it can be within a specific range. (example 0-100, or 0-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###**Creating the Model**\n",
    "\n",
    "Let's create a function that has within it many different machine learning models that we can use to make our predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a function within many Machine Learning Models\n",
    "def models(X_train,Y_train):\n",
    "  \n",
    "  #Using Logistic Regression Algorithm to the Training Set\n",
    "  from sklearn.linear_model import LogisticRegression\n",
    "  log = LogisticRegression(random_state = 0)\n",
    "  log.fit(X_train, Y_train)\n",
    "  \n",
    "  #Using KNeighborsClassifier Method of neighbors class to use Nearest Neighbor algorithm\n",
    "  from sklearn.neighbors import KNeighborsClassifier\n",
    "  knn = KNeighborsClassifier(n_neighbors = 5, metric = 'minkowski', p = 2)\n",
    "  knn.fit(X_train, Y_train)\n",
    "\n",
    "  #Using SVC method of svm class to use Support Vector Machine Algorithm\n",
    "  from sklearn.svm import SVC\n",
    "  svc_lin = SVC(kernel = 'linear', random_state = 0)\n",
    "  svc_lin.fit(X_train, Y_train)\n",
    "\n",
    "  #Using SVC method of svm class to use Kernel SVM Algorithm\n",
    "  from sklearn.svm import SVC\n",
    "  svc_rbf = SVC(kernel = 'rbf', random_state = 0)\n",
    "  svc_rbf.fit(X_train, Y_train)\n",
    "\n",
    "  #Using GaussianNB method of naïve_bayes class to use Naïve Bayes Algorithm\n",
    "  from sklearn.naive_bayes import GaussianNB\n",
    "  gauss = GaussianNB()\n",
    "  gauss.fit(X_train, Y_train)\n",
    "\n",
    "  #Using DecisionTreeClassifier of tree class to use Decision Tree Algorithm\n",
    "  from sklearn.tree import DecisionTreeClassifier\n",
    "  tree = DecisionTreeClassifier(criterion = 'entropy', random_state = 0)\n",
    "  tree.fit(X_train, Y_train)\n",
    "\n",
    "  #Using RandomForestClassifier method of ensemble class to use Random Forest Classification algorithm\n",
    "  from sklearn.ensemble import RandomForestClassifier\n",
    "  forest = RandomForestClassifier(n_estimators = 10, criterion = 'entropy', random_state = 0)\n",
    "  forest.fit(X_train, Y_train)\n",
    "  \n",
    "  #print model accuracy on the training data.\n",
    "  print('[0] Logistic Regression Training Accuracy:', log.score(X_train, Y_train))\n",
    "  print('[1] K Nearest Neighbor Training Accuracy:', knn.score(X_train, Y_train))\n",
    "  print('[2] Support Vector Machine (Linear Classifier) Training Accuracy:', svc_lin.score(X_train, Y_train))\n",
    "  print('[3] Support Vector Machine (RBF Classifier) Training Accuracy:', svc_rbf.score(X_train, Y_train))\n",
    "  print('[4] Gaussian Naive Bayes Training Accuracy:', gauss.score(X_train, Y_train))\n",
    "  print('[5] Decision Tree Classifier Training Accuracy:', tree.score(X_train, Y_train))\n",
    "  print('[6] Random Forest Classifier Training Accuracy:', forest.score(X_train, Y_train))\n",
    "  \n",
    "  return log, knn, svc_lin, svc_rbf, gauss, tree, forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###**Train the Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Train all the model on Training Data\n",
    "model = models(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output of the Training phase is as follows:\n",
    "    \n",
    "    [0] Logistic Regression Training Accuracy: 0.7963483146067416\n",
    "    [1] K Nearest Neighbor Training Accuracy: 0.8707865168539326\n",
    "    [2] Support Vector Machine (Linear Classifier) Training Accuracy: 0.7865168539325843\n",
    "    [3] Support Vector Machine (RBF Classifier) Training Accuracy: 0.8426966292134831\n",
    "    [4] Gaussian Naive Bayes Training Accuracy: 0.7893258426966292\n",
    "    [5] Decision Tree Classifier Training Accuracy: 0.9817415730337079\n",
    "    [6] Random Forest Classifier Training Accuracy: 0.9676966292134831\n",
    "        \n",
    "From the above observations we can observe that Decision Tree Classifier has attained an accuracy of 98.17% with highest accuracy among all.        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###**Evaluate the Model**\n",
    "\n",
    "Show the confusion matrix and accuracy for all the models on the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Priont the confustion matrix and test accuracy\n",
    "from sklearn.metrics import confusion_matrix \n",
    "for i in range(len(model)):\n",
    "   cm = confusion_matrix(y_test, model[i].predict(X_test)) \n",
    "   #extracting TN, FP, FN, TP\n",
    "   TN, FP, FN, TP = confusion_matrix(y_test, model[i].predict(X_test)).ravel()\n",
    "   print(f'Model[{i}] Testing Accuracy = \"{(TP + TN) / (TP + TN + FN + FP)}\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model that was most accurate on the test data is the model at position 6, which is the Random Forest Classifier with an accuracy of 82.68%. So, we will choose Random Forest Classifier as our final model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's find out the important features of the dataset, so that they can be used to predict the survivability of a passenger if he boards the Titanic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the importance of the features\n",
    "final_model = model[6]\n",
    "importances = pd.DataFrame({'feature':X.columns, 'importance':np.round(final_model.feature_importances_, 3)})\n",
    "importances = importances.sort_values('importance', ascending=False).set_index('feature')\n",
    "print(importances)\n",
    "\n",
    "# Plot the importances\n",
    "importances.plot.bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can observe that the important features are:\n",
    "\n",
    "    | Feature | Importance |\n",
    "    | ------- | ---------- |\n",
    "    | Age     |     0.300  |\n",
    "    | Fare    |     0.265  |\n",
    "    | Sex     |     0.237  |\n",
    "    | Pclass  |     0.078  |\n",
    "    | SibSp   |     0.054  |\n",
    "    | Parch   |     0.036  |\n",
    "    | Embarked|     0.031  |\n",
    "    \n",
    "<img src = \"images/5. Imp features.png\" width = \"600\" height = \"400\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the final model\n",
    "import pickle\n",
    "pickle.dump(final_model, open(\"Titanic_Survival_Predicion_RFC.pkl\", \"wb\"))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Titanic Survival Prediction.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
